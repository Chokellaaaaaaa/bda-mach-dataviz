{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3110a65",
   "metadata": {},
   "source": [
    "# Influence des infrastructures et aménagements routiers\n",
    "# -> Peut t'on predire la severite d'un accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0599ba43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "25/06/01 12:48:53 WARN Utils: Your hostname, DESKTOP-NHT3FJU resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/06/01 12:48:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/01 12:48:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"Accident\")\\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efd99743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------------+---------+-----------+------------------+---------------+-----------+-----+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+----+--------+--------+--------+-------+-------+----------+-------+----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+----------------------+----------------------+-------------------------+-----------------------------+-------------------------+----------------------+-------------+------------+----------------------+----------------------+-------------------------+-----------------------------+-------------------------+----------------------+---------------+--------------------+\n",
      "|Severity|Start_Time         |End_Time           |Start_Lat|Start_Lng  |Distance(mi)      |City           |County     |State|Temperature(F)|Wind_Chill(F)|Humidity(%)|Pressure(in)|Visibility(mi)|Wind_Direction|Wind_Speed(mph)|Precipitation(in)|Weather_Condition|Amenity|Bump|Crossing|Give_Way|Junction|No_Exit|Railway|Roundabout|Station|Stop|Traffic_Calming|Traffic_Signal|Turning_Loop|Sunrise_Sunset|Civil_Twilight|Nautical_Twilight|Astronomical_Twilight|Sunrise_Sunset_indexed|Civil_Twilight_indexed|Nautical_Twilight_indexed|Astronomical_Twilight_indexed|Weather_Condition_indexed|Wind_Direction_indexed|State_indexed|City_indexed|Sunrise_Sunset_encoded|Civil_Twilight_encoded|Nautical_Twilight_encoded|Astronomical_Twilight_encoded|Weather_Condition_encoded|Wind_Direction_encoded|State_encoded  |City_encoded        |\n",
      "+--------+-------------------+-------------------+---------+-----------+------------------+---------------+-----------+-----+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+----+--------+--------+--------+-------+-------+----------+-------+----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+----------------------+----------------------+-------------------------+-----------------------------+-------------------------+----------------------+-------------+------------+----------------------+----------------------+-------------------------+-----------------------------+-------------------------+----------------------+---------------+--------------------+\n",
      "|2       |2023-01-16 08:13:00|2023-01-16 10:19:01|34.103974|-118.190995|0.013             |Los Angeles    |Los Angeles|CA   |54.0          |54.0         |93.0       |29.52       |10.0          |VAR           |3.0            |0.0              |Cloudy           |0      |0   |0       |0       |0       |0      |0      |0         |0      |1   |0              |0             |0           |Day           |Day           |Day              |Day                  |0.0                   |0.0                   |0.0                      |0.0                          |2.0                      |18.0                  |0.0          |2.0         |(2,[0],[1.0])         |(2,[0],[1.0])         |(2,[0],[1.0])            |(2,[0],[1.0])                |(144,[2],[1.0])          |(24,[18],[1.0])       |(49,[0],[1.0]) |(13678,[2],[1.0])   |\n",
      "|2       |2022-05-11 15:26:00|2022-05-11 16:44:48|34.50334 |-117.974802|0.226             |Littlerock     |Los Angeles|CA   |59.0          |59.0         |20.0       |27.45       |10.0          |W             |22.0           |0.0              |Fair / Windy     |0      |0   |0       |0       |0       |0      |0      |0         |0      |0   |0              |0             |0           |Day           |Day           |Day              |Day                  |0.0                   |0.0                   |0.0                      |0.0                          |12.0                     |3.0                   |0.0          |1313.0      |(2,[0],[1.0])         |(2,[0],[1.0])         |(2,[0],[1.0])            |(2,[0],[1.0])                |(144,[12],[1.0])         |(24,[3],[1.0])        |(49,[0],[1.0]) |(13678,[1313],[1.0])|\n",
      "|2       |2023-01-15 14:33:30|2023-01-15 15:07:30|41.406877|-81.642026 |1.004             |Independence   |Cuyahoga   |OH   |33.0          |27.0         |72.0       |29.6        |10.0          |NNE           |7.0            |0.0              |Fair             |0      |0   |0       |0       |0       |0      |0      |0         |0      |0   |0              |0             |0           |Day           |Day           |Day              |Day                  |0.0                   |0.0                   |0.0                      |0.0                          |0.0                      |17.0                  |18.0         |331.0       |(2,[0],[1.0])         |(2,[0],[1.0])         |(2,[0],[1.0])            |(2,[0],[1.0])                |(144,[0],[1.0])          |(24,[17],[1.0])       |(49,[18],[1.0])|(13678,[331],[1.0]) |\n",
      "|2       |2022-05-19 06:28:00|2022-05-19 07:28:00|40.836564|-74.152819 |1.3969999999999998|Clifton        |Passaic    |NJ   |55.0          |55.0         |93.0       |29.79       |3.0           |S             |6.0            |0.21             |Rain             |0      |0   |0       |0       |0       |0      |0      |0         |0      |0   |0              |0             |0           |Day           |Day           |Day              |Day                  |0.0                   |0.0                   |0.0                      |0.0                          |10.0                     |1.0                   |16.0         |442.0       |(2,[0],[1.0])         |(2,[0],[1.0])         |(2,[0],[1.0])            |(2,[0],[1.0])                |(144,[10],[1.0])         |(24,[1],[1.0])        |(49,[16],[1.0])|(13678,[442],[1.0]) |\n",
      "|2       |2022-06-27 14:13:00|2022-06-27 17:06:00|40.12452 |-75.22971  |4.512             |Fort Washington|Montgomery |PA   |72.0          |72.0         |98.0       |29.63       |1.0           |NE            |3.0            |0.0              |Heavy Rain       |0      |0   |0       |0       |0       |0      |0      |0         |0      |0   |0              |0             |0           |Day           |Day           |Day              |Day                  |0.0                   |0.0                   |0.0                      |0.0                          |13.0                     |15.0                  |7.0          |410.0       |(2,[0],[1.0])         |(2,[0],[1.0])         |(2,[0],[1.0])            |(2,[0],[1.0])                |(144,[13],[1.0])         |(24,[15],[1.0])       |(49,[7],[1.0]) |(13678,[410],[1.0]) |\n",
      "+--------+-------------------+-------------------+---------+-----------+------------------+---------------+-----------+-----+--------------+-------------+-----------+------------+--------------+--------------+---------------+-----------------+-----------------+-------+----+--------+--------+--------+-------+-------+----------+-------+----+---------------+--------------+------------+--------------+--------------+-----------------+---------------------+----------------------+----------------------+-------------------------+-----------------------------+-------------------------+----------------------+-------------+------------+----------------------+----------------------+-------------------------+-----------------------------+-------------------------+----------------------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"../../data/processed_accidents.parquet\")\n",
    "df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1256159",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea072cb5",
   "metadata": {},
   "source": [
    "On ne garde que les colonnes qui semblent importante pour la prediction de la severite d'un accident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5320acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    \"Severity\",\n",
    "\n",
    "    'Start_Lat', 'Start_Lng', 'Distance(mi)',\n",
    "\n",
    "    'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)',\n",
    "    'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)',\n",
    "\n",
    "    'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit',\n",
    "    'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming',\n",
    "    'Traffic_Signal', 'Turning_Loop',\n",
    "\n",
    "    'Sunrise_Sunset_encoded', 'Civil_Twilight_encoded',\n",
    "    'Nautical_Twilight_encoded', 'Astronomical_Twilight_encoded',\n",
    "\n",
    "    'Weather_Condition_encoded', 'Wind_Direction_encoded',\n",
    "    'State_encoded'\n",
    "]\n",
    "\n",
    "df = df.select(columns_to_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db31c9d7",
   "metadata": {},
   "source": [
    "On plot la matrice de correlation avec toutes les colonnes selectionne juste avant pour s'assurer une bonne qualite des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a3a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "numerical_features = [\n",
    "    'Start_Lat', 'Start_Lng', 'Distance(mi)',\n",
    "    'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)',\n",
    "    'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)', 'Precipitation(in)',\n",
    "    'Severity'\n",
    "]\n",
    "\n",
    "sample_df = df.select(numerical_features).sample(withReplacement=False, fraction=0.1, seed=42)\n",
    "pandas_df = sample_df.toPandas()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(pandas_df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix of Numerical Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f0497b",
   "metadata": {},
   "source": [
    "On remarque que les colonnes `Wind_Chill(F)` et `Temperature(F)` sont tres correlees entres elles, alors on peut en supprimer une des deux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc5285b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"Wind_Chill(F)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfd9280",
   "metadata": {},
   "source": [
    "Pour le choix du model final, on va utiliser un subset du dataframe pour eviter des entrainements trop long lors du choix du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d87007af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(fraction=0.1, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adac6ab",
   "metadata": {},
   "source": [
    "On fait un split `80/20`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f45e0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sample, test_data_sample = df_sample.randomSplit([0.8, 0.2], seed=42)\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3858d656",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1aff176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_cols = columns_to_keep[1:]\n",
    "feature_cols.remove(\"Wind_Chill(F)\")\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e8c57",
   "metadata": {},
   "source": [
    "On choisie 4 modeles different pour notre analyse que voici:\n",
    "- Random Forest\n",
    "- GBT\n",
    "- Logistic Regression\n",
    "- OneVsRest avec une base de Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d117af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression, DecisionTreeClassifier, OneVsRest\n",
    "\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(labelCol=\"Severity\", featuresCol=\"features\"),\n",
    "    \"Logistic Regression\": LogisticRegression(labelCol=\"Severity\", featuresCol=\"features\"),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(labelCol=\"Severity\", featuresCol=\"features\"),\n",
    "    \"One-vs-Rest\": OneVsRest(\n",
    "        classifier=LogisticRegression(labelCol=\"Severity\", featuresCol=\"features\"),\n",
    "        labelCol=\"Severity\",\n",
    "        featuresCol=\"features\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2695bcb",
   "metadata": {},
   "source": [
    "On s'appuie sur le f1-score, le recall et la precision pour comparer nos differents model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8df10fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"Severity\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"Severity\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"Severity\", predictionCol=\"prediction\", metricName=\"weightedRecall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0280028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "def train_and_evaluate(model_name, model, train_data, test_data):\n",
    "    print(f\"Training model: {model_name}\")\n",
    "    pipeline = Pipeline(stages=[assembler, model])\n",
    "    pipeline_model = pipeline.fit(train_data)\n",
    "    predictions = pipeline_model.transform(test_data)\n",
    "    f1_score = evaluator_f1.evaluate(predictions)\n",
    "    precision = evaluator_precision.evaluate(predictions)\n",
    "    recall = evaluator_recall.evaluate(predictions)\n",
    "    return pipeline_model, f1_score, precision, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259a2b3",
   "metadata": {},
   "source": [
    "## Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b02e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    trained_model, f1_score, precision, recall = train_and_evaluate(model_name, model, train_data_sample, test_data_sample)\n",
    "    results[model_name] = {\n",
    "        \"model\": trained_model,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe35a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results).T.reset_index().rename(columns={\"index\": \"Model\"})\n",
    "df_melted = df_results.melt(id_vars=\"Model\", var_name=\"Metric\", value_name=\"Score\")\n",
    "df_melted = df_melted[df_melted[\"Metric\"] != \"model\"]\n",
    "df_melted[\"Score\"] = df_melted[\"Score\"].astype(float)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(data=df_melted, x=\"Model\", y=\"Score\", hue=\"Metric\", palette=\"Set2\")\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt=\"%.3f\", label_type=\"edge\", fontsize=9)\n",
    "\n",
    "plt.title(\"Model Performance Comparison\", fontsize=16)\n",
    "plt.ylim(0.6, 0.85)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xlabel(\"\")\n",
    "plt.legend(title=\"Metric\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1f2a4d",
   "metadata": {},
   "source": [
    "D’après tes résultats :\n",
    "- F1-score le plus élevé : Logistic Regression (≈ 0.729)\n",
    "- Bonne précision ET rappel\n",
    "\n",
    "On garde la Logistic Regression pour la suite de l'etude "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e92313",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d59245d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"Severity\", featuresCol=\"features\")\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1])\\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5])\\\n",
    "    .addGrid(lr.maxIter, [50, 100])\\\n",
    "    .addGrid(lr.tol, [1e-4, 1e-6])\\\n",
    "    .build()\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"Severity\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=lr,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator_f1,\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, cv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b684d01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipeline_model = pipeline.fit(train_data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ed31a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr_model = pipeline_model.stages[-1].bestModel\n",
    "best_params = best_lr_model.extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d372ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:\n",
      "aggregationDepth: 2\n",
      "elasticNetParam: 0.0\n",
      "family: auto\n",
      "featuresCol: features\n",
      "fitIntercept: True\n",
      "labelCol: Severity\n",
      "maxBlockSizeInMB: 0.0\n",
      "maxIter: 50\n",
      "predictionCol: prediction\n",
      "probabilityCol: probability\n",
      "rawPredictionCol: rawPrediction\n",
      "regParam: 0.01\n",
      "standardization: True\n",
      "threshold: 0.5\n",
      "tol: 1e-06\n"
     ]
    }
   ],
   "source": [
    "final_model = best_lr_model\n",
    "print(\"Best Parameters:\")\n",
    "\n",
    "for param, value in best_params.items():\n",
    "    print(f\"{param.name}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67abebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline = Pipeline(stages=[assembler, final_model])\n",
    "final_model = final_pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2de85a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Performance on Test Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3672:=================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.7274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# result of the final model\n",
    "print(\"Final Model Performance on Test Data:\")\n",
    "predictions = final_model.transform(test_data)\n",
    "f1_score = evaluator_f1.evaluate(predictions)\n",
    "print(f\"F1 Score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e8f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
